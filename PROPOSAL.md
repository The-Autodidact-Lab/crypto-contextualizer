# Background
Today's large language models have already begun to outclass human domain experts in a diverse range of fields and topics ranging from math and computer science/software engineering to customer support and outreach. To build on top of that, because of the dramatic depth well-trained and well-built foundation models can now reach (examples include Cursor's [Composer-1](https://cursor.com/blog/composer), Cognition's [SWE-1.5](https://cognition.ai/blog/swe-1-5), etc.), it is now feasible and even status quo to begin building compositional, multi-agent systems that are able to reflect expert-driven, *Society of Mind*-like [^1] architectures. Indeed, developments like Google's [A2A](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/), [Pydantic AI](https://ai.pydantic.dev/), [LangGraph](https://www.langchain.com/langgraph), [Autogen](https://microsoft.github.io/autogen/stable//index.html), and other multi-agent frameworks have brought about a new host of architectures and frameworks that drastically decrease the barrier to entry to create such systems. 

# The problem at hand
Despite all of this work, however, there is still a long way to go before we can reliably and effectively leverage multi-agent compute. Specifically, there are a few fundamental failings with today's LLMs themselves. Chiefly, there exist two major flaws that, in our opinion, prevent multi-agent systems from operating at full capacity; in this proposal, we will consider a template orchestrator-subagent system for demonstration to allow these problems to come to light. From here, we will term our orchestrator $O$, subagents $S_k$ for the $k$ th subagent, and tools $T_{kj}$ for the $j$ th tool used by $S_k$. Furthermore, we will assume that $O$ and $S_k : k \in \mathbb{N}$ are all of the same model and have their own ReAct [^2] loop processes running.

Let us begin by considering a simple delegation workflow, where $O$ receives an incoming user query, reasons, and delegates the task to $S_1$, who will use the tool $T_{11}$ in order to fetch a piece of information and the tool $T_{12}$ in order to complete the actual task (we will treat the process of delegation as a black box, as it has no implications on the actual issue at hand for now). Crucially, we notice that once $O$ has delegated to $S_1$, $S_1$ will undergo its own reasoning process that is entirely opaque for $O$ meaning that, especially in ill-designed systems, $O$ will be unable to understand the decision tree of $S_1$ and operate in any case; in success cases, $O$ will be unable to operate on anything but blind trial and error based on its own plan formation while in failure cases, $O$ fails to be able to debug because it will have minimal access to the control flows and logs that the error spawned. Through this simple example, we can see the much larger problem that arises in ill-constructed systems: a lack of consistent context throughout the different instances of the agent (for more information, Cognition's [recent blog post](https://cognition.ai/blog/dont-build-multi-agents) provides an extremely strong exposition of this problem). Indeed, it is this chief problem that our study will seek to address by a series of context manipulations and manoeuvring within a central cortex.

# Proposed solution/hypothesis
In order to solve the problem at hand, there are two main architectural design choices that we will seek to incorporate into the agentic loop and orchestrator system.

1. **Cryptographic context management within a single "trace cortex"**: Within this architecture, there are two separate problems that we address. Firstly, we seek to create an efficient and effective "trace cortex" across the whole multi-agent system that maintains traces from all agentic loop instances and categorises them as they are relevant to specific steps or actions within an execution pipeline. By first condensing and keeping the traces within a central cortex and furthermore organising them based on action, we hope to create an effective data structure that's able to offer a strong foundation for further fine-tuning in order to eliminate the context inconsistencies that we discussed above. After that, we seek to leverage ideas from cryptography, such as Huffman encodings and efficient bitwise operators (think [pigs and wine riddle](https://medium.com/i-math/a-king-1000-bottles-of-wine-10-prisoners-and-a-drop-of-poison-2dd1959a8dd2)), in order to create a system that allows different agents within the system to be able to quickly index into completely disjoint parts of the context tree while also leveraging the large overlap between different actions, tasks, and steps.

2. **Deterministic decision-tree search and bookkeeping**: As an extension, the system will seek to more clearly leverage solution space modelling/topology by using decision trees and tree search algorithms (a la [AlphaGo](https://deepmind.google/research/alphago/)) in order to more narrowly define viable paths and be more efficient in the actions that the agent takes. Specifically, this segment of the system will operate both as an extension to the original data structure described in part 1 and as a way to potentially allow for smaller, more interpretable/more deterministic RL models (like MCTS algorithms or graph-based algorithms) to augment the orchestrator's plan formation and decision-making process. We expect the specifics of this part of the system to evolve as we design the evals and benchmarks for part 1, but the overall framework should remain roughly as described above.

# Evaluations and benchmarks/experimental design
## Evaluations
In order to determine the effectiveness of this system, we will leverage [Meta's Agentic Research Environment (ARE)](https://ai.meta.com/research/publications/are-scaling-up-agent-environments-and-evaluations/) framework as a foundation in order to create a simple, consistent evaluation environment. All tools and tasks will be built directly off of the ARE and its defined standards, and any non-deterministic or "fuzzy" evaluations (such as semantic search, F1 scores, etc.) will be thoroguhly documented.

## Benchmarks
We will implement a series of simple text- and tool-based tasks across one-shot, few-shot, single-turn, and multi-turn use cases in a diverse field of domains in order to sufficiently simulate the realism of agentic use environments. Benchmark tests will be documented in a given structure, and any tests that require human intervention will be simulated both by predefined prompt inputs and guidelines (found in documentation) and by auxiliary helper models.

## Experimental design
As a baseline, we will begin by implementing both a basic single-agent ReAct loop and an orchestrator-subagent system where each subagent is tied to one specific "application" (in accordance with Meta ARE's terminology) using today's SOTA models. From there, we will add in the validator/cryptographic context tree system as an addition as a separate deterministic operation so as to not interfere with the system's tool usage performance. We will then run all of the systems on benchmarks from scratch and document their performance.

### References (included in Markdown RAW)
[^1]: https://www.academia.edu/20041800/Society_of_Mind
[^2]: https://arxiv.org/abs/2210.03629